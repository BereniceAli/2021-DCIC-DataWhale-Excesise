{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv转geopython\n",
    "#https://www.it1352.com/1505417.html\n",
    "#http://c.biancheng.net/view/5693.html(相对路径、绝对路径)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14072\n"
     ]
    }
   ],
   "source": [
    "import csv, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geojson import Feature, FeatureCollection, Polygon\n",
    "\n",
    "features = []\n",
    "data = pd.read_csv('../data/gxdc_tcd.csv', header = None)\n",
    "print(len(data))\n",
    "\n",
    "for i in range(1,len(data)):\n",
    "#     print(data[0][i])\n",
    "    lon1,lat1,lon2,lat2,lon3,lat3,lon4,lat4,lon5,lat5 = map(float, (data[1][i], data[2][i], data[3][i], data[4][i] , data[5][i], data[6][i], data[7][i], data[8][i], data[9][i], data[10][i]))\n",
    "#     polygon = np.array([lon1,lat1],[lon2,lat2],[lon3,lat3],[lon4,lat4],[lon5,lat5])\n",
    "    features.append(\n",
    "        Feature(\n",
    "            geometry = Polygon([[[lon1,lat1],[lon2,lat2],[lon3,lat3],[lon4,lat4],[lon5,lat5]]]),\n",
    "            properties = {\n",
    "                'FID': int(i),\n",
    "                'ID': data[0][i]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "collection = FeatureCollection(features)\n",
    "with open(\"../data/GeoObs.json\", \"w\") as f:\n",
    "    f.write('%s' % collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             BICYCLE_ID   LATITUDE   LONGITUDE  LOCK_STATUS  \\\n",
      "18748  0000ff105fd5f9099b866bccd157dc50  24.496578  118.142543            1   \n",
      "30333  0000ff105fd5f9099b866bccd157dc50  24.481350  118.167496            1   \n",
      "56536  0000ff105fd5f9099b866bccd157dc50  24.494801  118.147564            1   \n",
      "45519  0000ff105fd5f9099b866bccd157dc50  24.491365  118.149005            1   \n",
      "75690  0000ff105fd5f9099b866bccd157dc50  24.493236  118.141339            1   \n",
      "\n",
      "              UPDATE_TIME                       BICYCLE_ID1  LOCK_STATUS1  \\\n",
      "18748 2020-12-21 06:50:00  0000ff105fd5f9099b866bccd157dc50           1.0   \n",
      "30333 2020-12-21 08:44:00  0000ff105fd5f9099b866bccd157dc50           1.0   \n",
      "56536 2020-12-22 08:14:00  0000ff105fd5f9099b866bccd157dc50           1.0   \n",
      "45519 2020-12-22 08:23:00  0000ff105fd5f9099b866bccd157dc50           1.0   \n",
      "75690 2020-12-22 08:54:00  0000ff105fd5f9099b866bccd157dc50           1.0   \n",
      "\n",
      "       LATITUDE1  LONGITUDE1        UPDATE_TIME1  \n",
      "18748  24.481350  118.167496 2020-12-21 08:44:00  \n",
      "30333  24.494801  118.147564 2020-12-22 08:14:00  \n",
      "56536  24.491365  118.149005 2020-12-22 08:23:00  \n",
      "45519  24.493236  118.141339 2020-12-22 08:54:00  \n",
      "75690  24.498513  118.143140 2020-12-22 08:59:00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dingdan = pd.read_csv('../data/gxdc_dd_o.csv')\n",
    "\n",
    "def data_process_wyc(data):\n",
    "    data['UPDATE_TIME'] = pd.to_datetime(data['UPDATE_TIME'])\n",
    "    # 将数据排序,并把排序后的数据赋值给原来的数据\n",
    "    data = data.sort_values(by = ['BICYCLE_ID','UPDATE_TIME'])\n",
    "    \n",
    "    #让这几个字段的下一条数据赋值给新的字段，在字段名加个1，代表后面一条数据的值    \n",
    "    \n",
    "    data.loc[:,'BICYCLE_ID1'] = data['BICYCLE_ID'].shift(-1)\n",
    "    data.loc[:,'LOCK_STATUS1'] = data['LOCK_STATUS'].shift(-1)\n",
    "    data.loc[:,'LATITUDE1'] = data['LATITUDE'].shift(-1)\n",
    "    data.loc[:,'LONGITUDE1'] = data['LONGITUDE'].shift(-1)\n",
    "    data.loc[:,'UPDATE_TIME1'] = data['UPDATE_TIME'].shift(-1)\n",
    "    \n",
    "    print(data.head(5))\n",
    "    return data \n",
    "dingdan = data_process_wyc(dingdan)\n",
    "dingdan.to_csv('../data/共享单车订单gxdc_dd.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 判断条件，生成共享自行车OD数据\n",
    "\n",
    "基于完整的共享车租借OD记录进行电子停车位的绑定，原始数据中存在很多开锁不成功的记录对后续操作产生干扰，因此这里进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判断条件：\n",
    "dingdan = pd.read_csv('../data/共享单车订单gxdc_dd.csv')\n",
    "#1.这条数据和下一条数据的车辆ID必须是相同的\n",
    "dingdan.loc[:,'IF_STATUS'] = dingdan['LOCK_STATUS1']-dingdan['LOCK_STATUS']\n",
    "dingdan = dingdan[(dingdan['IF_STATUS'] == 1)]\n",
    "dingdan = dingdan[(dingdan['BICYCLE_ID1'] == dingdan['BICYCLE_ID'])]\n",
    "dingdan.to_csv('../data/共享单车gxdc_od.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据表连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>FENCE_ID</th>\n",
       "      <th>BELONG_ARE</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>Hubcount0</th>\n",
       "      <th>Hubcount1</th>\n",
       "      <th>in-out</th>\n",
       "      <th>in-out/area</th>\n",
       "      <th>in/area</th>\n",
       "      <th>FID</th>\n",
       "      <th>BICYCLE_ID</th>\n",
       "      <th>LOCK_STATU</th>\n",
       "      <th>LATITUDE1</th>\n",
       "      <th>LONGITUDE1</th>\n",
       "      <th>UPDATE_TIM</th>\n",
       "      <th>HubDist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>长乐路0_L_A17001</td>\n",
       "      <td>长乐路0</td>\n",
       "      <td>13.437863</td>\n",
       "      <td>7.964842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>长乐路0_L_A17002</td>\n",
       "      <td>长乐路0</td>\n",
       "      <td>13.408450</td>\n",
       "      <td>7.774982</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.385853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>长乐路0_L_A17003</td>\n",
       "      <td>长乐路0</td>\n",
       "      <td>13.786735</td>\n",
       "      <td>8.980655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>长乐路0_L_A17004</td>\n",
       "      <td>长乐路0</td>\n",
       "      <td>13.460416</td>\n",
       "      <td>8.696193</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.459971</td>\n",
       "      <td>0.229986</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>长乐路0_L_A17005</td>\n",
       "      <td>长乐路0</td>\n",
       "      <td>16.023975</td>\n",
       "      <td>10.931636</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.640343</td>\n",
       "      <td>0.091478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OBJECTID       FENCE_ID BELONG_ARE  Shape_Leng  Shape_Area  Hubcount0  \\\n",
       "FID_1                                                                          \n",
       "1             1  长乐路0_L_A17001       长乐路0   13.437863    7.964842        NaN   \n",
       "2             2  长乐路0_L_A17002       长乐路0   13.408450    7.774982        3.0   \n",
       "3             3  长乐路0_L_A17003       长乐路0   13.786735    8.980655        NaN   \n",
       "4             4  长乐路0_L_A17004       长乐路0   13.460416    8.696193        6.0   \n",
       "5             5  长乐路0_L_A17005       长乐路0   16.023975   10.931636        8.0   \n",
       "\n",
       "       Hubcount1  in-out  in-out/area   in/area  FID  BICYCLE_ID  LOCK_STATU  \\\n",
       "FID_1                                                                          \n",
       "1            NaN       0     0.000000  0.000000  NaN         NaN         NaN   \n",
       "2            NaN      -3    -0.385853  0.000000  NaN         NaN         NaN   \n",
       "3            NaN       0     0.000000  0.000000  NaN         NaN         NaN   \n",
       "4            2.0      -4    -0.459971  0.229986  2.0         2.0         2.0   \n",
       "5            1.0      -7    -0.640343  0.091478  1.0         1.0         1.0   \n",
       "\n",
       "       LATITUDE1  LONGITUDE1  UPDATE_TIM  HubDist  \n",
       "FID_1                                              \n",
       "1            NaN         NaN         NaN      NaN  \n",
       "2            NaN         NaN         NaN      NaN  \n",
       "3            NaN         NaN         NaN      NaN  \n",
       "4            2.0         2.0         2.0      2.0  \n",
       "5            1.0         1.0         1.0      1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "left = pd.read_csv('../data/hub_distance_origin1.csv', encoding = 'gbk')\n",
    "right = pd.read_csv('../data/gxdc_tcdindex.csv', encoding = 'gbk')\n",
    "left = left.set_index('HubFENCEID')\n",
    "right = right.set_index('HubFENCEID')\n",
    "merge = left.join(right,on='HubFENCEID', how = 'outer', lsuffix='_l', rsuffix='_r')\n",
    "merge.head(5)\n",
    "merge.to_csv('../data/gxdc_tcdtest.csv', encoding = 'gbk')\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "left = pd.read_csv('../data/gxdc_result2-1.csv', encoding = 'gbk')\n",
    "right = pd.read_csv('../data/../data/gxdc_tcdcount1.csv')\n",
    "left = left.set_index('FID_1')\n",
    "right = right.set_index('HubName')\n",
    "merge = left.join(right,on='FID_1', how = 'outer', lsuffix='_l', rsuffix='_r')\n",
    "merge.head(5)\n",
    "merge.to_csv('../data/gxdc_result2-1.csv', encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计每个停车位内的停车数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tcd = pd.read_csv('../data/hubdistance_od0-1.csv', encoding = 'gbk')\n",
    "# tcd['UPDATE_TIME'] = pd.to_datetime(tcd['UPDATE_TIME'])\n",
    "# tcd = tcd[tcd['UPDATE_TIME'].dt.hour.isin(np.arange(7, 9))]\n",
    "# print(len(tcd))\n",
    "count = tcd.groupby('HubName').count()\n",
    "count.to_csv('../data/gxdc_tcdcount0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计每个自定义区域内的停车位数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcd = pd.read_csv('../data/gxdc_tcdindex.csv', encoding = 'gbk')\n",
    "count = tcd.groupby('BELONG_ARE').count()\n",
    "count.to_csv('../data/gxdc_areacount.csv', encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计每个自定义区域内的停车数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tcd = pd.read_csv('../data/result2-1/gxdc_result2-1.csv', encoding = 'gbk')\n",
    "count = tcd.groupby(['BELONG_ARE'])['in/area'].sum().reset_index()\n",
    "\n",
    "count.to_csv('../data/result2-1/result1.csv', encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('../data/result2-1/gxdc_result2-1.csv', encoding = 'gbk')\n",
    "test.head(5)\n",
    "data = test[(test['percentinout'] > 3.5)]\n",
    "unique = data['BELONG_ARE'].unique()\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = pd.DataFrame(unique)\n",
    "unique.to_csv('../data/result2-1/area2-2.csv', encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据订单数据计算骑行时间\n",
    "\n",
    "这里考虑时间问题是基于平时租借共享自行车会遇到开锁后发现自行车无法骑行，原地关闭的情况，\n",
    "所以做了时间统计，但其实对于区域潮汐统计骑行时间一长的判断意义不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime\n",
    "\n",
    "test = pd.read_csv('../data/共享单车gxdc_od.csv', encoding = 'gbk')\n",
    "test['UPDATE_TIME'] = pd.to_datetime(test['UPDATE_TIME'])\n",
    "test['UPDATE_TIME1'] = pd.to_datetime(test['UPDATE_TIME1'])\n",
    "# 计算时间差，添加round表示四舍五入\n",
    "# test['bikingtime'] = round((test['UPDATE_TIME1'] - test['UPDATE_TIME']).dt.total_seconds() / (Time_Bandwith * 60))\n",
    "test['bikingtime'] = (test['UPDATE_TIME1'] - test['UPDATE_TIME']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../data/共享单车gxdc_od.csv', encoding = 'gbk', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用geohash对订单数据进行停车点的匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#共享单车停车点位（电子围栏）数据为规范共享单车停车秩序，统一划定的共享单车停放区域。\n",
    "# 读取数据\n",
    "def bike_fence_format(s):\n",
    "    s = s.replace('[', '').replace(']', '').split(',')\n",
    "    s = np.array(s).astype(float).reshape(5, -1)\n",
    "    return s\n",
    "\n",
    "# 共享单车停车点位（电子围栏）数据\n",
    "bike_fence = pd.read_csv(PATH + 'gxdc_tcd_0.csv')\n",
    "bike_fence['FENCE_LOC'] = bike_fence['FENCE_LOC'].apply(bike_fence_format)\n",
    "\n",
    "# 得出停车点 LATITUDE 范围\n",
    "bike_fence['MIN_LATITUDE'] = bike_fence['FENCE_LOC'].apply(lambda x: np.min(x[:, 1]))\n",
    "bike_fence['MAX_LATITUDE'] = bike_fence['FENCE_LOC'].apply(lambda x: np.max(x[:, 1]))\n",
    "\n",
    "# 得到停车点 LONGITUDE 范围\n",
    "bike_fence['MIN_LONGITUDE'] = bike_fence['FENCE_LOC'].apply(lambda x: np.min(x[:, 0]))\n",
    "bike_fence['MAX_LONGITUDE'] = bike_fence['FENCE_LOC'].apply(lambda x: np.max(x[:, 0]))\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "# 根据停车点 范围 计算具体的面积\n",
    "bike_fence['FENCE_AREA'] = bike_fence.apply(lambda x: geodesic(\n",
    "    (x['MIN_LATITUDE'], x['MIN_LONGITUDE']), (x['MAX_LATITUDE'], x['MAX_LONGITUDE'])\n",
    ").meters, axis=1)\n",
    "\n",
    "# 根据停车点 计算中心经纬度\n",
    "bike_fence['FENCE_CENTER'] = bike_fence['FENCE_LOC'].apply(\n",
    "    lambda x: np.mean(x[:-1, ::-1], 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共享单车订单数据\n",
    "bike_order = pd.read_csv(PATH + '共享单车订单gxdc_dd.csv')\n",
    "bike_order = bike_order.sort_values(['BICYCLE_ID', 'UPDATE_TIME'])\n",
    "\n",
    "# geohash经纬度匹配\n",
    "bike_order['geohash'] = bike_order.apply(\n",
    "    lambda x: geohash.encode(x['LATITUDE'], x['LONGITUDE'], precision=6), \n",
    "axis=1)\n",
    "\n",
    "bike_fence['geohash'] = bike_fence['FENCE_CENTER'].apply(\n",
    "    lambda x: geohash.encode(x[0], x[1], precision=6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 区域流量统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_order['UPDATE_TIME'] = pd.to_datetime(bike_order['UPDATE_TIME'])\n",
    "bike_order['DAY'] = bike_order['UPDATE_TIME'].dt.day.astype(object)\n",
    "bike_order['DAY'] = bike_order['DAY'].apply(str)\n",
    "\n",
    "bike_order['HOUR'] = bike_order['UPDATE_TIME'].dt.hour.astype(object)\n",
    "bike_order['HOUR'] = bike_order['HOUR'].apply(str)\n",
    "bike_order['HOUR'] = bike_order['HOUR'].str.pad(width=2,side='left',fillchar='0')\n",
    "\n",
    "# 日期和时间进行拼接\n",
    "bike_order['DAY_HOUR'] = bike_order['DAY'] + bike_order['HOUR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用透视表统计每个区域在不同时间的入流量和出流量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_inflow = pd.pivot_table(bike_order[bike_order['LOCK_STATUS'] == 1], \n",
    "                   values='LOCK_STATUS', index=['geohash'],\n",
    "                    columns=['DAY_HOUR'], aggfunc='count', fill_value=0\n",
    ")\n",
    "\n",
    "bike_outflow = pd.pivot_table(bike_order[bike_order['LOCK_STATUS'] == 0], \n",
    "                   values='LOCK_STATUS', index=['geohash'],\n",
    "                    columns=['DAY_HOUR'], aggfunc='count', fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "根据入流量和出流量，可以计算得到每个位置的留存流量，即(入流量-出流量)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_remain = (bike_inflow - bike_outflow).fillna(0)\n",
    "\n",
    "# 存在骑走的车数量 大于 进来的车数量\n",
    "bike_remain[bike_remain < 0] = 0  \n",
    "\n",
    "# 按照天求平均\n",
    "bike_remain = bike_remain.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这里先提取产生潮汐现象的停车位，根据共享自行车的占地面积情况，一般长度达1米左右，宽度应该在0.2-0.3米左右，所以1平米的正方形电子停车位大概能停3-4辆车，但是电子停车位的形状只有少量为接近正方形的形状，长方形的例如0.5m*2m的电子停车位则大概可以停4辆车，所以当留存车辆数/停车位面积之比大于4的时候，认为停车情况超出停车位的承载能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 留存车辆 / 街道停车位总面积，计算得到密度\n",
    "bike_density = bike_fence.groupby(['STREET'])['geohash'].unique().apply(\n",
    "    lambda hs: np.sum([bike_remain[x] for x in hs])\n",
    ") / bike_fence.groupby(['STREET'])['FENCE_AREA'].sum()\n",
    "\n",
    "# 按照密度倒序\n",
    "bike_density = bike_density.sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 然后提取bike_density大于4.0的电子停车位标注FENCE_TYPE为1，其余标注为0，进行测试后得分为18.7759"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
